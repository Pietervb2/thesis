\chapter{Control Methods}\label{chap::optimization}
This section discusses control methods used to lower the return temperature in district heating networks, which actuate the bypass control valve and the supply temperature. Afterwards, the application of Bayesian Optimization will be discussed. 

\section{Bypass Flow Control}
These valves are used to redirect supply water to the return network to prevent a drop in the supply water temperature during a period of low heat demand. However, the flow redirected by the bypass valve should also be limited as it increases the return temperature, therefore causing a higher overall energy loss in the network and a decrease in efficiency of the heat pump. As mentioned in Section \ref{sec::overflowmech}, the bypass valves found in the Cooltower are thermostatic bypass valves and installed at the branch ends. 

Articles revolving around the control of thermostatic bypasses in district heating networks are scarcely present in the literature. Even though proper control of the bypasses can play an important role in lowering the return temperature \cite{app15062982,VANDERMEULEN201845}. In \cite{VANDERMEULEN201845}, the authors propose a theoretical benchmark for the performance of bypass controllers and compare it with a thermostatic bypass valve. Where Li et al. \cite{DTUlibrary} show the impact of varying thermostatic bypass flows (installed at the branch ends) on the return temperature for different heat loads, but they do not perform an optimization. Brand et al. \cite{BRAND2014256} also investigated the effect of thermostatic bypass valves, comparing them with different bypass valve configurations linked to bathroom floor heating to improve energy efficiency of the overall system. They came to the conclusion that the thermostatic bypass cannot be completely replaced by the floor heating as its flow was limited. In \cite{BENAKOPOULOS2021120928} Benakopoulos et al. do optimize thermostatic regulation valves to achieve a better return temperature, but these are connected to the radiators on the customer side. Rong et al. \cite{RONG2025116197} created an optimization model to maximize the heat storage capacity and economic efficiency of the DHN by selectively placing bypasses and controlling the flow through these bypasses using valves. 

\todo[inline]{hier nog wat toevoegen}

\section{Supply Temperature Control}
Supply temperature control maintains the network temperature at the required level by injecting or extracting the appropriate amount of heat. Traditional supply temperature control is often done via a weather compensation technique, which adjusts the supply temperature based on outdoor conditions. The weather compensation curves can vary significantly depending on the research, and in case of wrong commissioning of the curves, they can perform worse than constant supply temperatures, resulting in higher return temperatures \cite{app15062982, LIAO200555}. Liao et al. \cite{LIAO200555} apply another strategy by proposing an adaptive control method that relies on real-time measurements of space heat load to adjust the supply temperature. It results in better meeting the heat demand. Tol et al. \cite{TOL2021105} also make use of real-time data. They present a novel demand-responsive control strategy that reacts to changes in the difference between the return and supply temperatures at substations. This doesn't necessarily lead to a lower return temperature compared to the weather compensation curves, but it reduces electricity use. The authors of \cite{papaKonstantikou} made a controller that determines the lowest supply temperature based on heat demand predictions and network time-delay calculations. 


\section{Bayesian Optimization Overview}
% All the information in this section is drawn from the tutorial on Bayesian Optimization (BO) written by Brochu, Cora, and de Freitas \cite{bo_tutorial}. The citations from this section are also drawn from them. 

Bayesian Optimization (BO) is used to find the extrema of objective functions that are expensive or time-consuming to evaluate. It can be applied in situations where there is no closed-form expression of the objective function, but it is possible to gather some data points of the function. BO techniques are highly efficient considering the number of samples needed to find an extreme. This is largely due to incorporating a prior belief about the problem, helping data sampling, and maintaining a balance while sampling the search space between exploration (sampling x at high uncertainty of the objective function) and exploitation (sampling x where the objective function is likely to be high). The technique revolves around Bayes' Theorem, stated below, hence its name. 

\begin{equation}
P(f \mid \mathcal{D}_{1:t}) \propto P(\mathcal{D}_{1:t}\mid f) P(f) .
\end{equation}
With $x_i$ as the ith sample, $f(x_i)$ as the observation of the objective function at $x_i$ and $\mathcal{D}_{1:t}$ the collection of sampling points and observations $\mathcal{D}_{1:t} = \{x_{1:t},f(x_{1:t})\}$. The prior $P(f)$ is combined with the likelihood function $P(D_{1:t}\mid f)$, resulting in the posterior $P(f \mid \mathcal{D}_{1:t})$ capturing the information we have of the objective function. After each iteration, new observations are incorporated into the posterior, which refines our belief about the objective function. Bayesian Optimization generally uses Gaussian Processes (GP) as the prior of the objective function. A Gaussian Process is a distribution over Gaussian functions, completely specified by its mean function $m(x)$ and the covariance function $k(x,x')$ \cite{bo_tutorial}. 

\begin{equation}
    f(x) \sim \mathcal{GP}(m(x), k(x,x'))
\end{equation}
For convenience, the prior mean is assumed to be zero; applications in which this is not the case are, for example, \cite{MartinezCantin, Brochu2010}. The choice of covariance function is more crucial for the prior, as it determines the smoothness properties of samples drawn from the GP. Depending on the type of system you want to optimize, the kernel might vary. A common example of a kernel is the squared exponential kernel (\ref{eq::isotropic}). With $\theta$ as a hyperparameter affecting the width of the kernel. In the case of anisotropic models, this hyperparameter becomes a diagonal matrix \cite{rasmussen2006gaussian}. The entries of $diag(\theta)$ control how much influence the features have over the covariance.
\begin{equation}\label{eq::isotropic}
k\left(\mathrm{x}_i, \mathrm{x}_j\right)=\exp \left(-\frac{1}{2 \theta^2}\left\|\mathrm{x}_i-\mathrm{x}_j\right\|^2\right),
\end{equation}
\begin{equation}\label{eq::anistropic}
k\left(\mathrm{x}_i, \mathrm{x}_j\right)=\exp \left(-\frac{1}{2}\left(\mathrm{x}_i-\mathrm{x}_j\right)^T \operatorname{diag}(\theta)^{-2}\left(\mathrm{x}-\mathrm{x}^{\prime}\right)\right).
\end{equation}
The values of the hyperparameters are usually defined by starting with random guesses of a few random samples and maximizing the log likelihood of the evidence given $\theta$ \cite{rasmussen2006gaussian, santner2003design}. The kernel choice is typically done using hierarchical Bayesian model selection \cite{mackay1992practical} or cross-validation. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\linewidth]{Literature Survey - DCSC template/figuresLIT/BayesianOptmization.png}
    \caption{An example of Bayesian Optimization. A Gaussian Process approximating the objective function of a 1D problem after four iterations using sampled values of the objective function. In this example, the sought extreme is the maximum \cite{bo_tutorial}.}
    \label{fig::BO}
\end{figure}

The next sample location $x_{t+1}$ is determined using an acquisition function. These functions are defined in a way that they yield high values for potentially high (or low, depending on the extreme of interest) values of the objective functions. This can be due to a high predicted objective function value, large uncertainty of this value, or a combination of both. Maximizing the acquisition function results in the next sample location. A proper trade-off between exploration and exploitation within this process is essential to BO, as it allows the method to efficiently scan the search space for potential extrema \cite{bo_tutorial}. 
Moƒçkus et al. \cite{Mockus1978} proposed to maximize the expected improvement with respect to the best value known thus far. Lizotte \cite{Lizotte2008} introduces an extra parameter to improve the trade-off. Cox and John \cite{CoxJohn1997} present an algorithm that selects evaluation points based on the lower confidence bound of the prediction site. 

Figure \ref{fig::BO} shows three iterative steps of the BO technique. On the x-axis, the optimized feature is plotted, and on the y-axis, its performance is plotted. The black dotted line is the objective function, and the black line is the posterior mean. Around the posterior mean, the light purple region shows the upper and lower bounds of the posterior uncertainty. At each step, the next sampling point is chosen based on the maximum of the acquisition function. This information is then used to update the posterior, as can be clearly observed from the changes in its uncertainty


\section{Bayesian Optimization In Literature}
The literature on Bayesian Optimization used in the context of district heating networks is scarce. The few articles applying the technique use it to find the hyperparameters for an artificial neural network (ANN). Li et al. \cite{LIbayesian} use it to optimize their LSTM for short-term heating load forecasting, and Abokersh et al. \cite{ABOKERSH2020403} develop an ANN model based on BO to find an alternative for the computationally expensive heuristic optimization models used for solar district heating systems. The master's thesis from de Koning \cite{deKoning2020} uses BO to determine the hyperparameters of an LSTM model that accurately simulates large district heating networks, which generally tend to experience high computational costs. The developed LSTM was not able to achieve a lower cost. Aslan et al. \cite{Aslan06062025} use BO to improve the hyperparameters of boiler efficiency degradation models present in district heating and cooling substations, to increase the efficiency and reliability of energy systems.

